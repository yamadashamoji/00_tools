{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nON9d-seALH_"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6J4FFPGveodPP56Sg2noy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yamadashamoji/00_tools/blob/main/hateful_words_filtering_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 悪意のある言葉フィルタリングアプリ(簡易版)\n",
        "\n",
        "# 依存ライブラリのインストール（Colabで最初に実行）\n",
        "!pip install -q transformers torch ipywidgets fugashi unidic-lite huggingface_hub\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Hugging Faceトークンの入力（不要な場合もあり）\n",
        "# print(\"Hugging Faceのアクセストークンを入力してください（公開モデルの場合はEnterでスキップ）:\")\n",
        "# hf_token = getpass() or None\n",
        "# if hf_token:\n",
        "#     login(token=hf_token)  # トークンで認証\n",
        "\n",
        "# 禁止ワードリスト（フレーズを追加）\n",
        "prohibited_words = [\"バカ\", \"アホ\", \"殴る\", \"殺す\", \"バカすぎる\", \"ムカつく\"]\n",
        "\n",
        "# BERTモデルとトークナイザーのロード\n",
        "model_name = \"kit-nlp/bert-base-japanese-sentiment-cyberbullying\"\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, token=hf_token)\n",
        "except Exception as e:\n",
        "    print(f\"モデル '{model_name}' のロードに失敗しました: {e}\")\n",
        "    print(\"トークンが正しいか、リポジトリへのアクセス権があるか確認してください。\")\n",
        "    raise e\n",
        "\n",
        "# 感情分析関数\n",
        "def analyze_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=1).squeeze().tolist()\n",
        "    # kit-nlp/bert-base-japanese-sentiment-cyberbullying: 0=ネガティブ, 1=ポジティブ\n",
        "    return {\"positive\": probabilities[1], \"negative\": probabilities[0]}\n",
        "\n",
        "# テキストを文に分割\n",
        "def split_into_sentences(text):\n",
        "    sentences = re.split(r'[。！？\\n]+', text)\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "# 禁止ワードを置き換え\n",
        "def replace_prohibited_words(text, prohibited_words):\n",
        "    replaced_text = text\n",
        "    replaced_words = []\n",
        "    for word in prohibited_words:\n",
        "        if word in replaced_text:\n",
        "            replaced_text = replaced_text.replace(word, \"[見せられないよ]\")\n",
        "            replaced_words.append(word)\n",
        "    return replaced_text, replaced_words\n",
        "\n",
        "# メイン処理\n",
        "def process_text(input_text):\n",
        "    sentences = split_into_sentences(input_text)\n",
        "    processed_sentences = []\n",
        "    all_replaced_words = []\n",
        "    detailed_log = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # 感情分析\n",
        "        sentiment = analyze_sentiment(sentence)\n",
        "        negative_prob = sentiment[\"negative\"]\n",
        "        # フィルタリング条件: 禁止ワードを含む場合、閾値を0.5に下げる\n",
        "        threshold = 0.5 if any(word in sentence for word in prohibited_words) else 0.7\n",
        "        if negative_prob >= threshold and any(word in sentence for word in prohibited_words):\n",
        "            processed_sentence, replaced_words = replace_prohibited_words(sentence, prohibited_words)\n",
        "            all_replaced_words.extend(replaced_words)\n",
        "            # 詳細ログに文脈情報を追加\n",
        "            detailed_log.append(\n",
        "                f\"文: {sentence}<br>\"\n",
        "                f\"ネガティブ確率: {negative_prob:.2f}（閾値: {threshold}）<br>\"\n",
        "                f\"置き換えた単語: {', '.join(replaced_words) if replaced_words else 'なし'}<br>\"\n",
        "                f\"処理後: {processed_sentence}<br>\"\n",
        "            )\n",
        "        else:\n",
        "            processed_sentence = sentence\n",
        "            # ネガティブ確率が低い場合の理由を追加\n",
        "            reason = \"フィルタリング不要（ネガティブ確率が閾値未満または禁止ワードなし）\"\n",
        "            if negative_prob < threshold:\n",
        "                reason += f\"<br>注: このモデルはネットいじめ特有の強い攻撃的表現に敏感です。軽度の侮辱（例: 'バカ'）はネガティブとみなされない場合があります。\"\n",
        "            detailed_log.append(\n",
        "                f\"文: {sentence}<br>\"\n",
        "                f\"ネガティブ確率: {negative_prob:.2f}（閾値: {threshold}）<br>\"\n",
        "                f\"処理: {reason}<br>\"\n",
        "            )\n",
        "        processed_sentences.append(processed_sentence)\n",
        "\n",
        "    # 結果を結合\n",
        "    result_text = \"。\".join(processed_sentences)\n",
        "    if result_text and not result_text.endswith(\"。\"):\n",
        "        result_text += \"。\"\n",
        "\n",
        "    # ログ出力（HTMLで色付け）\n",
        "    result_text_html = result_text.replace(\"[見せられないよ]\", \"<span style='color:red'>[見せられないよ]</span>\")\n",
        "    log = f\"<b>処理結果:</b> {result_text_html}<br>\"\n",
        "    if all_replaced_words:\n",
        "        log += f\"<b>置き換えた単語（全体）:</b> {', '.join(set(all_replaced_words))}<br>\"\n",
        "    else:\n",
        "        log += \"<b>置き換えた単語（全体）:</b> なし<br>\"\n",
        "    log += \"<b>詳細ログ:</b><br>\" + \"<hr>\".join(detailed_log)\n",
        "\n",
        "    return log\n",
        "\n",
        "# UIウィジェット\n",
        "input_box = widgets.Textarea(\n",
        "    value=\"\",\n",
        "    placeholder=\"ここにテキストを入力してください（例: お前バカすぎるよ。バカでも分かる説明。）\",\n",
        "    description=\"入力:\",\n",
        "    layout={'width': '500px', 'height': '100px'}\n",
        ")\n",
        "output_area = widgets.HTML(value=\"\")\n",
        "process_button = widgets.Button(description=\"処理開始\")\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    input_text = input_box.value\n",
        "    if input_text:\n",
        "        result = process_text(input_text)\n",
        "        output_area.value = result\n",
        "    else:\n",
        "        output_area.value = \"<b>エラー:</b> テキストを入力してください\"\n",
        "\n",
        "process_button.on_click(on_button_clicked)\n",
        "\n",
        "# UI表示\n",
        "display(HTML(\"<h3>悪意のある言葉フィルタリングアプリ</h3>\"))\n",
        "display(input_box)\n",
        "display(process_button)\n",
        "display(output_area)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fXMvFFMWGjaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "悪意のある言葉フィルタリングアプリ 仕様書（正規版）\n",
        "1. 概要\n",
        "本アプリは、ユーザーが入力した日本語テキストをリアルタイムで分析し、悪意のある言葉や不適切な表現を検出して「見せられないよ」などのメッセージに置き換えるWebアプリケーションです。感情分析にはBERT（cl-tohoku/bert-base-japanese）を用い、特定の禁止ワードリストに基づくフィルタリングを組み合わせます。\n",
        "2. 目的\n",
        "\n",
        "ユーザーが入力するテキストから悪意のある言葉を検出し、適切な代替表現に置き換える。\n",
        "日本語の感情分析を通じて、ネガティブな感情を含む文脈を高精度に識別。\n",
        "安全で快適なコミュニケーション環境を提供。\n",
        "\n",
        "3. 機能要件\n",
        "3.1 テキスト入力と処理\n",
        "\n",
        "入力: ユーザーがテキストボックスに日本語テキストを入力。\n",
        "出力: 処理後のテキストをリアルタイムで表示。悪意のある言葉は「見せられないよ」に置き換え。\n",
        "処理速度: 入力から1秒以内に結果を表示。\n",
        "\n",
        "3.2 感情分析\n",
        "\n",
        "モデル: transformersライブラリとcl-tohoku/bert-base-japaneseを使用。\n",
        "分類: テキストをポジティブ/ネガティブ/ニュートラルに分類。\n",
        "閾値: ネガティブと判定された確率が0.7以上の場合、悪意のある可能性が高いとみなす。\n",
        "対象: 文単位で分析（長編テキストは文に分割して処理）。\n",
        "\n",
        "3.3 禁止ワードフィルタリング\n",
        "\n",
        "ワードリスト: 事前に定義された禁止ワードリスト（例: 侮辱、差別、暴力的な表現）を使用。\n",
        "処理: 感情分析でネガティブと判定された文に含まれる禁止ワードを「見せられないよ」に置き換え。\n",
        "カスタマイズ: ユーザーがワードリストを追加/編集可能（管理画面経由）。\n",
        "\n",
        "3.4 ユーザーインターフェース\n",
        "\n",
        "テキストボックス: ユーザーがテキストを入力するエリア。\n",
        "結果表示エリア: 処理後のテキストを表示。\n",
        "フィードバック: 置き換えが発生した場合、どの部分が置き換えられたかをハイライト表示。\n",
        "管理画面: 禁止ワードリストの編集やモデルの設定変更。\n",
        "\n",
        "4. 非機能要件\n",
        "\n",
        "パフォーマンス: 最大512トークンのテキストを1秒以内に処理。\n",
        "スケーラビリティ: クラウド環境（例: AWS, GCP）でのデプロイを想定し、同時ユーザー100人に対応。\n",
        "セキュリティ: 入力テキストは一時保存のみで、処理後に削除。禁止ワードリストは暗号化して保存。\n",
        "互換性: 主要ブラウザ（Chrome, Firefox, Safari）で動作。\n",
        "\n",
        "5. 技術スタック\n",
        "\n",
        "フロントエンド: React, Tailwind CSS（軽量でモダンなUI）。\n",
        "バックエンド: Python (FastAPI)、transformers、PyTorch。\n",
        "モデル: cl-tohoku/bert-base-japanese（日本語BERT）。\n",
        "デプロイ: Dockerコンテナ、クラウド（AWS/GCP）。\n",
        "データベース: SQLite（禁止ワードリスト管理用、軽量）。\n",
        "\n",
        "6. 処理フロー\n",
        "\n",
        "ユーザーがテキストを入力。\n",
        "テキストを文単位に分割（句点や改行で分割）。\n",
        "各文をBERTモデルで感情分析（ポジティブ/ネガティブ/ニュートラル）。\n",
        "ネガティブと判定された文に対し、禁止ワードリストと照合。\n",
        "該当するワードを「見せられないよ」に置き換え。\n",
        "処理済みテキストをUIに表示（置き換え部分はハイライト）。\n",
        "\n",
        "7. リスクと課題\n",
        "\n",
        "感情分析の精度: BERTモデルの精度に依存。誤検知/未検知を減らすため、追加のファインチューニングが必要。\n",
        "禁止ワードの網羅性: リストの更新頻度や方言・スラングへの対応が課題。\n",
        "処理速度: 長編テキストや高負荷時のパフォーマンス確保。\n",
        "文化的ニュアンス: 日本語特有の表現や文脈の解釈ミスを防ぐ。\n",
        "\n",
        "8. 拡張性\n",
        "\n",
        "多言語対応（他のBERTモデルを追加）。\n",
        "リアルタイムチャットアプリへの組み込み。\n",
        "学習済みモデルの定期的な更新と再学習。\n",
        "\n",
        "9. 開発スケジュール（仮）\n",
        "\n",
        "Week 1-2: 環境構築、BERTモデルとtransformersのセットアップ。\n",
        "Week 3-4: 感情分析と禁止ワードフィルタリングの実装。\n",
        "Week 5: UI開発（React + Tailwind CSS）。\n",
        "Week 6: 統合テスト、デプロイ準備。\n",
        "Week 7: ユーザーテスト、フィードバック反映。\n",
        "\n",
        "10. 付録\n",
        "10.1 禁止ワードリストの例\n",
        "\n",
        "侮辱: 「バカ」「アホ」\n",
        "差別: （具体例は倫理的配慮から省略）\n",
        "暴力: 「殴る」「殺す」\n",
        "\n",
        "10.2 サンプル入力と出力\n",
        "入力: 「お前バカすぎるよ、ほんとムカつく。」出力: 「お前[見せられないよ]すぎるよ、ほんと[見せられないよ]。」\n"
      ],
      "metadata": {
        "id": "Do7icpCbAu-Y"
      }
    }
  ]
}